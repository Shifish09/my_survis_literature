@article{Rampriya2024An,
  abstract = {Safety is crucial in the railway industry. To guarantee passenger safety, computer vision, unmanned aerial vehicles (UAV), and artificial intelligence will be essential tools. This paper presents an unmanned aerial vehicle captured dataset for railroad segmentation and obstacle detection (UAV - RSOD). It contains high - resolution images of railroad scenes with various obstacles. The dataset includes 315 raw images, 630 labeled and 630 masked images for railroad semantic segmentation, and 315 original images for object and obstacle detection. After data augmentation, there are 2002 augmented and annotated images for obstacle detection, covering six obstacle classes. Each image is accurately annotated. The dataset is made publicly available, facilitating research and development in railroad - related computer vision applications.},
  author = {Rampriya, R. S. and Taher Al - Shehari and Sabari Nathan and Jenefa, A. and Suganya, R. and Shunmuga Perumal, P. and Taha Alfakih and Hussain Alsalman},
  doi = {10.1038/s41597-024-03952-3},
  journal = {Scientific Data},
  number = {11},
  pages = {1315},
  publisher = {Springer Nature},
  title = {An unmanned aerial vehicle captured dataset for railroad segmentation and obstacle detection},
  url = {https://doi.org/10.1038/s41597-024-03952-3},
  volume = {2024},
  year = {2024},
  keywords = {railroad segmentation; obstacle detection; UAV dataset; computer vision; data augmentation}
}
@article{Tang2024ASurvey,
  abstract = {This paper reviews the development of object detection for unmanned aerial vehicles (UAVs) based on deep learning. It analyzes the differences between UAV object detection and common object detection, as well as the challenges in UAV object detection. The paper surveys deep - learning - based methods in UAV object detection, including one - stage and two - stage algorithms, and analyzes their solutions to problems like small object detection, complex backgrounds, object rotation, and category imbalance. It also introduces public datasets for UAV object detection and discusses future research directions.},
  author = {Tang, Guangyi and Ni, Jianjun and Zhao, Yonghao and Gu, Yang and Cao, Weidong},
  doi = {10.3390/rs16010149},
  journal = {Remote Sensing},
  number = {01},
  pages = {149},
  publisher = {MDPI},
  title = {A Survey of Object Detection for UAVs Based on Deep Learning},
  url = {https://doi.org/10.3390/rs16010149},
  volume = {16},
  year = {2024},
  keywords = {object detection; unmanned aerial vehicles; deep learning; computer vision}
}
@article{Ramachandran2021AReview,
  abstract = {This paper reviews object detection in unmanned aerial vehicle (UAV) surveillance. It classifies object detection methods applied in UAV images, lists relevant datasets, summarizes existing research works in different applications, and proposes a secure onboard processing system for a robust object detection framework in precision agriculture.},
  author = {Ramachandran, Anitha and Sangaiah, Arun Kumar},
  doi = {10.1016/j.ijcce.2021.11.005},
  journal = {International Journal of Cognitive Computing in Engineering},
  pages = {215 - 228},
  publisher = {Elsevier B.V. on behalf of KeAi Communications Co. Ltd.},
  title = {A review on object detection in unmanned aerial vehicle surveillance},
  url = {https://www.sciencedirect.com/science/article/pii/S2666307421000937},
  volume = {2},
  year = {2021},
  keywords = {Object detection; UAV; Drone; Deep learning; Precision agriculture; Security}
}
@article{Chen2024Residual,
  abstract = {Object detection in unmanned aerial vehicle (UAV) images, a subset of small object detection, is challenging due to the prevalence of small objects and dense occlusion. This paper presents Residual Spatial Reduced Transformer based on YOLOv5 (RSRT - YOLOv5). It uses the Slice Aided Enhancement Module (SAEM) to enhance small object features, the Global attention - based Bi - directional Feature Fusion (GBFF) module for better feature fusion, and the Residual Spatial Reduced Transformer (RSRT) module for effective global contextual association. Experiments on the Visdrone2019 dataset show that RSRT - YOLOv5 outperforms the baseline YOLOv5 model, improving UAV image detection performance.},
  author = {Chen, Li and Cang, Naimeng and Zhang, Wenbo and Zhang, Chan and Zhang, Weidong and Guo, Dongsheng},
  doi = {10.1142/S0218001424500071},
  journal = {International Journal of Pattern Recognition and Artificial Intelligence},
  number = {05},
  pages = {2450007},
  publisher = {World Scientific Publishing Company},
  title = {Residual Spatial Reduced Transformer Based on YOLOv5 for UAV Images Object Detection},
  url = {https://doi.org/10.1142/S0218001424500071},
  volume = {38},
  year = {2024},
  keywords = {Residual spatial reduced transformer; yolov5; object detection; unmanned aerial vehicle (UAV) images}
}
@article{Dong2025EA-YOLO,
  abstract = {This paper presents an improved UAV image object detection algorithm, EA - YOLO, based on YOLOv5. It addresses issues like target scale changes, low detection accuracy, and high miss rates in UAV aerial photography. The algorithm includes a DFE module for better feature extraction, a CWFF architecture for enhanced feature fusion, and an SDS structure for improved small - target detection. Experiments on the VisDrone2019 dataset show that EA - YOLOs achieves higher accuracy metrics (mAP@0.5 and mAP@0.5:0.95) compared to YOLOv5s and other YOLO versions, with reduced computational costs. It also shows good generalization on the AI - TOD dataset.},
  author = {Dong, Dehao and Li, Jianzhuang and Liu, Haiying and Deng, Lixia and Gu, Jason and Liu, Lida and Li, Shuang},
  doi = {10.1002/tee.24180},
  journal = {IEEJ Transactions on Electrical and Electronic Engineering},
  pages = {61 - 68},
  publisher = {Institute of Electrical Engineers of Japan and Wiley Periodicals LLC},
  title = {EA - YOLO: An Efficient and Accurate UAV Image Object Detection Algorithm},
  url = {https://doi.org/10.1002/tee.24180},
  volume = {20},
  year = {2025},
  keywords = {YOLOv5; small object detection; UAV image; real-time detection; deep learning}
}
@article{Bouhlel2024MOD-IR,
  abstract = {This paper presents the MOD-IR method for detecting moving objects from UAV - captured video sequences. It involves four steps: feature extraction and matching, frame registration, moving objects detection, and post - processing. The method enhances effectiveness and robustness by extracting robust features and automatically defining thresholds. It is efficient for real - time applications and uses parallel quick - shift segmentation. Experiments on multiple datasets show its competitive performance compared to state - of - the - art methods in terms of F - measure, Gmean, and runtime.},
  author = {Bouhlel, Fatma and Mliki, Hazar and Hammami, Mohamed},
  doi = {10.1007/s11042-023-16667-1},
  journal = {Multimedia Tools and Applications},
  pages = {46779 - 46798},
  publisher = {Springer Science+Business Media, LLC, part of Springer Nature},
  title = {MOD-IR: moving objects detection from UAV-captured video sequences based on image registration},
  url = {https://doi.org/10.1007/s11042-023-16667-1},
  volume = {83},
  year = {2024},
  keywords = {Moving objects detection; UAV; Feature extraction and matching; Image registration; Max entropy thresholding; Quick - shift segmentation}
}
@article{Leira2021Object,
  abstract = {This paper presents a multiple object detection, recognition, and tracking system for UAVs. It uses a thermal camera and onboard computational unit to detect objects in the camera's image stream, georeference their locations, and track them using a Kalman filter and global - nearest - neighbor algorithm. Four field tests were conducted, and the results show the system can effectively detect and track boats, with an accuracy of 5 - 15 m in position estimation from 400 m altitude when the boat is in the camera's FOV.},
  author = {Leira, Frederik S. and Helgesen, Håkon Hagen and Johansen, Tor Arne and Fossen, Thor I.},
  doi = {10.1002/rob.21985},
  journal = {Journal of Field Robotics},
  pages = {242 - 267},
  publisher = {Wiley Periodicals LLC},
  title = {Object detection, recognition, and tracking from UAVs using a thermal camera},
  url = {https://doi.org/10.1002/rob.21985},
  volume = {38},
  year = {2021},
  keywords = {aerial robotics; computer vision; position estimation}
}
@article{Bomantara2023Detection,
  abstract = {This study focuses on detecting artificial seed - like objects (I - Seeds) from UAV RGB images in real - time using the YOLO object detection algorithm. Four variants of YOLOv5 were compared, considering environmental parameters like daylight condition, background type, and flying altitude. The YOLOv5n variant showed the best performance, achieving high accuracy, especially under certain conditions. The study provides a baseline for future small - object detection research in similar scenarios.},
  author = {Bomantara, Yanuar A. and Mustafa, Hasib and Bartholomeus, Harm and Kooistra, Lammert},
  doi = {10.3390/rs15061637},
  journal = {Remote Sensing},
  volume = {15},
  number = {06},
  pages = {1637},
  publisher = {MDPI},
  title = {Detection of Artificial Seed - like Objects from UAV Imagery},
  url = {https://doi.org/10.3390/rs15061637},
  year = {2023},
  keywords = {unmanned aerial vehicles; object detection; deep learning; flying height; light conditions; background type}
}
@article{Zhou2023AMulti-Scale,
  abstract = {This paper presents a multi-scale object detector named CGMDet for UAV aerial images. It addresses issues like large-scale variation and complex backgrounds. The detector includes a Coordinate and Global Information Aggregation Module (CGAM) and a Feature Fusion Module (FFM), and modifies the bounding box regression loss. Experiments on VisDrone and UAVDT datasets show that CGMDet improves mAP0.5 by 1.9% and 3.0% respectively, outperforming many existing models.},
  author = {Zhou, Liming and Liu, Zhehao and Zhao, Hang and Hou, Yan-E and Liu, Yang and Zuo, Xianyu and Dang, Lanxue},
  doi = {10.3390/rs15143468},
  journal = {Remote Sensing},
  volume = {15},
  number = {14},
  pages = {3468},
  publisher = {MDPI},
  title = {A Multi-Scale Object Detector Based on Coordinate and Global Information Aggregation for UAV Aerial Images},
  url = {https://doi.org/10.3390/rs15143468},
  year = {2023},
  keywords = {UAV images; multi-feature fusion; information aggregation; multi-scale object detection}
}
@article{Khoramshahi2023ANovel,
  abstract = {This study presents a novel machine - learning approach using UAV RGB images to detect alien barleys in oat fields. It combines an Unbiased Teacher v2 semi - supervised object - detection deep CNN with photogrammetric techniques and clustering methods. The method was tested on two datasets, achieving 82.9% detection rate in the reference dataset and 60.5% in the independent test dataset, demonstrating its potential for modern grain production.},
  author = {Khoramshahi, Ehsan and Näsi, Roope and Rua, Stefan and Oliveira, Raquel A. and Päivänsalo, Axel and Niemeläinen, Oiva and Niskanen, Markku and Honkavaara, Eija},
  doi = {10.3390/rs15143582},
  journal = {Remote Sensing},
  volume = {15},
  number = {14},
  pages = {3582},
  publisher = {MDPI},
  title = {A Novel Deep Multi - Image Object Detection Approach for Detecting Alien Barleys in Oat Fields Using RGB UAV Images},
  url = {https://doi.org/10.3390/rs15143582},
  year = {2023},
  keywords = {photogrammetry; UAV; remote sensing; plant species classification; drone; deep learning; semi - supervised classification}
}
